{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Neurolab env",
      "language": "python",
      "name": "neurolab"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "psr_mpl_eeg_nikita.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pakrentos/eeg_connectivity/blob/master/psr_mpl_eeg_nikita.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Hg09agJucvr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "809e99f0-d814-47f6-ee9d-ca2cae325241"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0qjVTWBwG7L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "5944e0da-1d78-4c55-b7b9-aae84b924c7d"
      },
      "source": [
        "!rm -rf /content/src\n",
        "!git init\n",
        "!git remote add origin https://github.com/pakrentos/eeg_connectivity/\n",
        "!git fetch origin\n",
        "!git checkout origin/master -- src"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initialized empty Git repository in /content/.git/\n",
            "remote: Enumerating objects: 92, done.\u001b[K\n",
            "remote: Counting objects: 100% (92/92), done.\u001b[K\n",
            "remote: Compressing objects: 100% (76/76), done.\u001b[K\n",
            "remote: Total 92 (delta 41), reused 35 (delta 14), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (92/92), done.\n",
            "From https://github.com/pakrentos/eeg_connectivity\n",
            " * [new branch]      evgen      -> origin/evgen\n",
            " * [new branch]      master     -> origin/master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dd0SN-ouTWX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from src import *\n",
        "from src.psr import lagged_ami\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import r2_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "from src.psr import global_false_nearest_neighbors, lagged_ami\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from statistics import stdev, mean\n",
        "import json\n",
        "from src.eeg_utils import r_mapping\n",
        "from tensorflow import keras"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-9qX3mZuTWb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub_dir = '/content/drive/My Drive/Subjects'\n",
        "subject_scores = []\n",
        "f = open('/content/drive/My Drive/уга-буга/channels.json', 'r')\n",
        "### ПОМЕНЯЙ ЭТОТ ПАРАМЕТР С :250 НА 250: АУФ\n",
        "channels_arr = np.array(json.load(f))[:250]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lwvw_HmfuTWe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def separate(arr, bins):\n",
        "    return np.array(np.split(arr, bins))\n",
        "\n",
        "def prepare(arr):\n",
        "    arr = np.random.permutation(arr)\n",
        "    cutoff = arr.shape[0]//2\n",
        "    train = arr[cutoff:]\n",
        "    val = arr[:cutoff]\n",
        "    src = train[:, 0, :]\n",
        "    trgt = train[:, 1, :]\n",
        "    src_val = val[:, 0, :]\n",
        "    trgt_val = val[:, 1, :]\n",
        "    return src, trgt, src_val, trgt_val\n",
        "\n",
        "my_callbacks = [\n",
        "                EarlyStopDifference(patience=10, delta=0.001, verbose=0),\n",
        "            ]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yE21mDzuTWh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Смотрим на всех субъектов\n",
        "%%time\n",
        "overall = {}\n",
        "for sub_num in range(1, 11):\n",
        "    edata = extract_all(group='YOUNG', hand='righthand', subject=sub_num, sub_dir=sub_dir)\n",
        "    temp_sub_dict = {}\n",
        "    print(f'@@@ Subject {sub_num} @@@')\n",
        "    iter = 0\n",
        "    for ch_pair in channels_arr:\n",
        "        ch1 = ch_pair[0]\n",
        "        ch2 = ch_pair[1]\n",
        "        print(f'    ### Channel pair {ch1} {ch2} . Num of ch_pair: {iter} ###')\n",
        "        iter += 1\n",
        "        ch1_data = select_channel(edata, ch1)\n",
        "        ch2_data = select_channel(edata, ch2)\n",
        "        # Фильтруем в нужном нам диапазоне\n",
        "        lc = 4.0\n",
        "        hc = 8.0\n",
        "        ch1_data = butter_bandpass_filter(ch1_data, lc, hc, 250)\n",
        "        ch2_data = butter_bandpass_filter(ch2_data, lc, hc, 250)\n",
        "        # Нормализуем\n",
        "        ch1_data = normalize(ch1_data[:, 250*2:])\n",
        "        ch2_data = normalize(ch2_data[:, 250*2:])\n",
        "        # Выбираем коеффициенты для psr. Если коеффициенты не совпадают для каналов на определенном триале -- этот триал откидывается\n",
        "        coefs_arr = []\n",
        "        for i in range(len(ch1_data)):\n",
        "            ch1_lag, ch1_dim = determine_coefs(ch1_data[i], max_lag=10, max_dims=20)\n",
        "            ch2_lag, ch2_dim = determine_coefs(ch2_data[i], max_lag=10, max_dims=20)\n",
        "            # print(f'Trial #{i}. {ch1} lag: {ch1_lag}, dims: {ch1_dim}. {ch2} lag: {ch2_lag}, dims: {ch2_dim}')\n",
        "            if ch1_lag != ch2_lag:\n",
        "                # print(f'WARNING: Lag of {ch1} does not equal to lag of {ch2}')\n",
        "                continue\n",
        "            if ch1_dim != ch2_dim:\n",
        "                # print(f'WARNING: Num of dims of {ch1} does not equal to number of dims of {ch2}')\n",
        "\n",
        "                ch1_dim, ch2_dim = max((ch1_dim, ch2_dim)), max((ch1_dim, ch2_dim))\n",
        "            coefs_arr.append((i, ch1_lag, ch1_dim, ch2_lag, ch2_dim))\n",
        "        # Эти числа нужны будут для разбивки данных на окна\n",
        "        bins_arr = np.arange(2, 10)\n",
        "        scores = []\n",
        "        for data_ind, ch1_lag, ch1_dim, ch2_lag, ch2_dim in coefs_arr:\n",
        "            # PSR\n",
        "            ch1_recon = reconstruct(ch1_data[data_ind], ch1_lag, ch1_dim)\n",
        "            ch2_recon = reconstruct(ch2_data[data_ind], ch2_lag, ch2_dim)\n",
        "            # Подготовка данных для запихивания в нейронку\n",
        "            data = np.stack((ch1_recon, ch2_recon), axis=-2)\n",
        "            scores_temp = []\n",
        "            for bins in bins_arr:\n",
        "                temp = []\n",
        "                # Разбиение данных на окна\n",
        "                length = (data.shape[0]//bins)*bins\n",
        "                # print(f'Trial #{data_ind}. Current bin: {bins}. ', end='')\n",
        "                for d in separate(data[:length], bins):\n",
        "                    src, trgt, src_val, trgt_val = prepare(d)\n",
        "                    model = baseline_model(inputs=data.shape[-1], outputs=data.shape[-1])\n",
        "                    hist = model.fit(src, trgt, validation_data=(src_val, trgt_val), epochs=50, callbacks=my_callbacks, batch_size=100, verbose=False)\n",
        "                    r = model.predict(src_val)\n",
        "                    score = r2_score(trgt_val.T, r.T)\n",
        "                    temp.append(score)\n",
        "                scores_mean = np.mean(temp)\n",
        "                scores_stdev = stdev(temp)\n",
        "                # print(f'Mean score: {scores_mean}. Stdev: {scores_stdev}')\n",
        "                scores_temp.append(temp)\n",
        "            scores.append(scores_temp)\n",
        "        temp_sub_dict[f'{ch1} {ch2}'] = scores\n",
        "        overall[sub_num] = temp_sub_dict\n",
        "        f = open('/content/drive/My Drive/уга-буга/test.json', 'w')\n",
        "        json.dump(overall, f)\n",
        "        f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCww6gs-uTWm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EarlyStopDifference(keras.callbacks.Callback):\n",
        "    # Custom callback that stops training if the difference between training and validation\n",
        "    # loss function is more than delta for the past patience training epochs\n",
        "    \n",
        "    ### Parameters:\n",
        "    ### delta: Integer, default=0; Minimal affordable difference between loss functions\n",
        "    ### patience: Integer, default=0; Number of epochs it is tolerable to have difference greater than delta\n",
        "    ### verbose: Integer, default=0; Prints output if it is 1\n",
        "    \n",
        "    def __init__(self, patience=0, delta=0, verbose=0):\n",
        "        # Initializing parameters\n",
        "        super(EarlyStopDifference, self).__init__()\n",
        "        self.patience=patience\n",
        "        self.delta=delta\n",
        "        self.verbose=verbose\n",
        "        self.counter=0\n",
        "    \n",
        "    def on_train_begin(self, logs=None):\n",
        "        # The number of epoch it has waited when loss is no longer minimum.\n",
        "        self.wait = 0\n",
        "        # The epoch the training stops at.\n",
        "        self.stopped_epoch = 0\n",
        "        # Initialize the best as infinity.\n",
        "        self.best = np.Inf\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        # Recieving loss function values\n",
        "        mse = logs['loss']\n",
        "        val_mse = logs['val_loss']\n",
        "        # Comparing them to delta\n",
        "        if ((mse - val_mse) <= self.delta):\n",
        "            # Resetting counter\n",
        "            self.wait = 0\n",
        "        else:\n",
        "            # Incrementing counter\n",
        "            self.wait += 1\n",
        "            if self.wait >= self.patience:\n",
        "                # Stopping the model if wait >= patience\n",
        "                self.stopped_epoch = epoch\n",
        "                self.model.stop_training = True\n",
        "                if (self.verbose != 0):\n",
        "                    print(\"Model stopped because mse and val_mse differ for more than \", self.delta, \" for the past \", self.patience, \" training epochs.\")\n",
        "            \n",
        "    def on_train_end(self, logs=None):\n",
        "        # Printing the epoch the model has stopped\n",
        "        if (self.stopped_epoch > 0) & (self.verbose != 0):\n",
        "            print(\"Epoch %05d: early stopping\" % (self.stopped_epoch + 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ChVz6rtBar0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "9e3a799d-6296-4585-fb10-200dcdd85718"
      },
      "source": [
        "%%time\n",
        "print('sas')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sas\n",
            "CPU times: user 911 µs, sys: 24 µs, total: 935 µs\n",
            "Wall time: 724 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5f34h0KBcun",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}